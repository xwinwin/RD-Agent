describe: # some template to describe some object
  # exp is a template used fo
  exp: |-
    ## {{ heading | default('Best solution of previous exploration of the scenario') }}
    {% if exp %}### Code
    Here is the complete code of the solution.
    {{ exp.experiment_workspace.all_codes }}

    {% if exp.hypothesis is not none %}
    ### Hypothesis for the experiment
    the experiment is designed based on hypothesis: {{exp.hypothesis}}
    {% endif %}

    ### Results
    {% if exp.result is none %}
    There are no according evaluation results
    {% else %}
    Evaluated results on validation are:
    {{ exp.result }}
    {% if exp.format_check_result is not none %}
    Submission format check result is:
    {{ exp.format_check_result }}
    {% endif %}
    {% if exp.running_info.running_time is not none %}
    Running time: {{ exp.running_info.running_time }} seconds
    {% endif %}
    {% endif %}

    {% else %}No previous complete experiment available.
    {% endif %}

  feedback: |-
    {% if exp_and_feedback and exp_and_feedback|length > 1 %}
    ## {{heading | default('Previous trial and feedback')}}
    {% if exp_and_feedback[0].hypothesis %}
    The experiment is designed based on hypothesis: {{ exp_and_feedback[0].hypothesis }}
    {% endif %}
    Feedback decision: {{ exp_and_feedback[1].decision }}
    {% if exp_and_feedback[1].code_change_summary  %}Code change summary: {{ exp_and_feedback[1].code_change_summary }}{% endif %}
    Reason: {{ exp_and_feedback[1].reason }}
    {% endif %}

  trace: |-
    {% if exp_and_feedback_list|length == 0 %}
    No previous {% if type == "success" %}SOTA{% elif type == "failed" %}failed{% endif %} experiments available.
    {% else %}
    {% for exp_and_feedback in exp_and_feedback_list %}
    ## Experiment Index: {{ loop.index }}
    Target Problem: {{ exp_and_feedback[0].hypothesis.problem_desc }}
    {% if not pipeline %}Chosen Component: {{ exp_and_feedback[0].hypothesis.component }}{% endif %}
    Proposed Hypothesis: {{ exp_and_feedback[0].hypothesis.hypothesis }}
    {% if exp_and_feedback[1].code_change_summary  %}Code Change Summary: {{ exp_and_feedback[1].code_change_summary }}{% endif %}
    **Surpass Previous SOTA**: {{ exp_and_feedback[1].decision }}    
    {% if exp_and_feedback[0].running_info.running_time is not none %}
    Experiment Running Time: {{ (exp_and_feedback[0].running_info.running_time ) | round(1) }} seconds
    {% endif %}
    {% if exp_and_feedback[0].result is none %}
    Experiment Score: Running buggy
    Experiment Error: {{ exp_and_feedback[1].reason }}
    {% else %}
    Experiment Score: {{ exp_and_feedback[0].result.loc["ensemble"].iloc[0] }}
    Experiment Feedback: {{ exp_and_feedback[1].reason }}
    {% endif %}
    {% endfor %}
    {% endif %}

  scen:  # customizable
  role: |-
    你是一名Kaggle大师（Kaggle Grandmaster）和专家ML工程师，在统计、机器学习和竞赛优化方面有深厚的专业知识。
  input_path: "./workspace_input/"
  cache_path: "./workspace_cache/"

component_description:
  DataLoadSpec: |-
    加载原始竞赛数据，确保正确的数据类型，并提供探索性数据分析（EDA）摘要。
    - 当专注于此组件时，相应的编辑文件将是："load_data.py"
  FeatureEng: |-
    将原始数据转换为有意义的特征，同时保持形状一致性、避免数据泄露，并优化模型性能。
    它应该是模型无关的（仅适用于特定模型框架的数据转换/增强不应包含在此处）。
    确保你建议的特征工程更改可以在不修改模型代码的情况下实现。如果更改需要修改模型代码，则认为它们是特定于模型的。我们应该专注于模型组件来应用这些更改。
    - 当专注于此组件时，相应的编辑文件将是："feature.py"
  Model: |-
    执行以下三项任务之一：模型构建，即开发一个解决问题的模型；模型调优，即优化现有模型以获得更好的性能；或模型移除，即丢弃无效的模型。
    处理以下数据操作或增强：
    1) 与模型框架紧密相关的工具，例如PyTorch或TensorFlow提供的工具（如Dataset和DataLoader）。
    2) 无法在特征工程（"feature.py"）中应用而不修改模型代码的操作。
    - 当专注于此组件时，相应的编辑文件将是："model_*.py"
  Ensemble: |-
    使用集成策略组合多个模型的预测，评估其性能，并生成最终的测试预测。
    - 当专注于此组件时，相应的编辑文件将是："ensemble.py"
  Workflow: |-
    集成所有管道组件，从数据加载到集成预测，确保高效执行和正确的输出格式。
    - 当专注于此组件时，相应的编辑文件将是："main.py"

component_description_in_pipeline: |-
  [DataLoadSpec]: 专注于管道的数据加载和预处理方面，确保数据正确格式化并准备好进行特征工程。
  [FeatureEng]: 专注于将原始数据转换为有意义的特征，同时保持数据集的完整性。
  [Model]: 专注于模型的构建和管道的调优，确保模型针对性能进行了优化。
  [Ensemble]: 专注于组合多个模型的预测并评估其性能。
  [Workflow]: 专注于整体管道集成或未包含在其他组件中的部分，确保所有组件协同工作。

component_spec:
  general: |-
    {{ spec }}

    你的代码将通过以下代码进行测试。你必须确保你的实现通过测试代码：
    ```python
    {{ test_code }}
    ```
  DataLoadSpec: |-
    1. 文件处理：
      - 适当处理文件编码和分隔符。
      - 如有必要，合并或处理多个文件。
      - 避免使用sample submission文件来推断测试索引。如果有专用的测试索引文件，请使用该文件；否则，使用测试文件中的顺序作为测试索引。
      - 如果每个预测样本与磁盘上的文件链接，只需将文件路径作为X/特征加载（请加载完整路径，以便在后续工作流中更轻松地编写加载器），无需任何额外处理。

    2. 数据预处理：
      - 正确转换数据类型（例如，数值型、分类型、日期解析）。
      - 使用诸如降压或分块读取数据等技术优化大型数据集的内存使用。
      - 领域特定处理：
        - 根据需要应用竞赛特定的预处理步骤（例如，文本分词、图像调整大小）。
        - 不要直接返回二进制字节，而是将它们转换/解码为更有用的格式，如numpy.ndarrays。

    3. 代码规范：
      - 不要使用进度条（例如 `tqdm`）。
      - 不要使用sample submission文件提取测试索引信息。
      - 在此过程中不要意外排除特征。

    4. 探索性数据分析（EDA）[必需]：
      - 在返回数据之前，你应始终添加描述数据的EDA部分，以帮助后续步骤更好地理解数据。
      - EDA部分应以纯文本形式起草，具有一定的格式模式，不超过一万个字符。
      - 评估agent将帮助检查EDA部分是否正确添加。

    5. 注意事项
      - 切勿使用sample submission作为测试索引，因为它可能与测试数据不同。使用测试索引文件或测试数据源获取测试索引。

  FeatureEng: |-
    1. 妥善处理数据形状
      - 训练数据和测试数据的样本数量在所有场景中应该相同。
      - 对于某些表格或时间序列数据，你可以添加或删除一些列，因此推断的列数可能不确定。
      - 对于每个维度没有特殊含义的场景（如图像、音频等），输入形状和输出形状在大多数情况下应该完全相同，除非有令人信服的理由改变它们。

    2. 与模型管道的集成：
      - 如果特征工程推迟到模型管道中以获得更好的整体性能，请明确说明它将在模型阶段处理。
        - 模型相关的操作不应在此步骤中实现。（例如，使用与模型结合的工具，如torch.Dataset，其具有丰富的数据转换/增强功能）
      - 否则，确保此函数应用所有必要的转换，同时避免数据泄露。

    3. 一般注意事项：
      - 确保大型数据集的可扩展性。
      - 适当处理缺失值和异常值（例如，填充、移除或替换）。
      - 确保特征数据类型和转换之间的一致性。
      - 防止数据泄露：不要在使用测试集信息转换训练数据时使用这些信息。

    4. 代码规范：
      - 在实现中避免使用进度条（例如 `tqdm`）。

    5. 注意事项：
      - GPU和多进程可用，强烈建议用于加速转换。
      - 特征工程应**只执行一次**并在所有模型中重复使用以确保一致性：`X_transformed, y_transformed, X_test_transformed = feat_eng(X, y, X_test)`
      - 如果数据加载器直接返回文件路径，我们可以跳过特征工程并直接返回原始值。
  
  Model: |-
    - 不要在实现中使用进度条（例如 `tqdm`）。
    - 设备支持GPU，因此如有必要，强烈建议使用它进行训练以加速过程。
    - 某些数据转换/增强可以包含在此步骤中（例如，TensorFlow和Torch提供的数据工具）
      - 请正确处理数据转换/增强，尤其是当数据加载器直接加载文件路径时。
    - 确保动态处理特征维度，以适应输入特征的潜在增强，而无需修改代码。
  
  Ensemble: |-
    1. 输入验证：
      - 妥善处理空输入或无效输入，并提供适当的错误消息。

    2. 指标计算和存储：
      - 计算每个模型和集成策略在验证集上的指标（竞赛信息的评估部分中提到），并将结果保存在 `scores.csv` 中，例如：
      ```python
      scores = {}
      for model_name, val_pred in val_preds_dict.items():
          scores[model_name] = calculate_metric(val_label, val_pred)
      
      ...
      一些关于集成策略的代码
      ...
      ensemble_val_pred = ...

      ensemble_score = calculate_metric(val_label, ensemble_val_pred)
      scores["ensemble"] = ensemble_score  # 确保"ensemble"被显式存储
      
      scores_df = pd.DataFrame(scores.items(), columns=["Model", <metric_name>])
      scores_df.to_csv("scores.csv", index=False)
      ```
      - 即使只有一个模型，也要计算集成分数并将其存储在"ensemble"下。

    3. 代码规范：
      - 不要在代码中使用进度条（例如，tqdm）。

    4. 注意事项：
      - 确保灵活性以根据竞赛要求处理多种集成策略。
    
  Workflow: |-
    你的任务是为Kaggle风格的机器学习竞赛项目实现主工作流脚本（`main.py`）。
    遵循提供的项目结构和规范以确保一致性和可维护性：
    1. 工作流集成：
      - 将以下组件集成到工作流中：
        - 数据加载（`load_data.py`）。
        - 特征工程（`feature.py`）。
        - 用于训练和测试的模型工作流（`model_*.py`）。
        - 组合模型工作流结果以获得最终预测的集成工作流（`ensemble.py`）。
      - 将每个组件视为模块化且可调用的Python函数。
      - 工作流脚本应足够灵活以处理单个模型或多个模型，文件名（model_*.py）最初不确定。
        对于多个模型选择，使用Python代码根据文件名识别符合条件的模型，例如：
        ```python
        available_models = [f for f in os.listdir('.') if f.startswith('model_') and 'test' not in f]
        ```
      - 工作流脚本应可直接执行。我们将按原样运行你的脚本，因此不要假设你的函数将被单独导入和调用。
    2. 特征工程
      - 特征工程应只调用一次。例如：
        `X_transformed, y_transformed, X_test_transformed = feat_eng(X, y, X_test)`
      - 它应该在数据集拆分之前调用。

    3. 数据集拆分
      - `load_data`返回的数据集没有预先拆分。调用`feat_eng`后，将数据拆分为训练集和测试集。
      - [注意] 如果可行，在训练集（`X_transformed`，`y_transformed`）上应用交叉验证，以确保模型性能评估的可靠性。
      - 保持测试集（`X_test_transformed`）不变，因为它仅用于生成最终预测。
      - 参考伪代码逻辑：
        ```
        设置分割数量并初始化KFold交叉验证器。
        创建验证和测试预测的字典。
        对于每个模型文件：
            动态导入模型。
            初始化Out-of-Fold（OOF）和测试预测的数组。
            对于KFold中的每个折叠：
                将数据拆分为训练集和验证集。
                运行模型工作流以获得验证和测试预测。
                验证形状。
                存储验证和测试预测。
            计算跨折叠的平均测试预测。
            保存OOF和平均测试预测。
        集成所有模型的预测并打印最终形状。
        ```

    4. 提交文件：
      - 将最终预测保存为`submission.csv`，确保格式符合竞赛要求，如竞赛信息的'====== Submission Format ======'部分所述（**不要在代码中直接读取sample_submission.csv文件**）。
      - 显式呈现所需的提交格式并确保输出符合要求。

    5. 代码规范：
      - 不要在代码中使用进度条（例如，tqdm）。

    6. 集成策略：
      - 将所有模型输出整合到一个字典中，其中每个键是模型的文件名（不含.py扩展名），其对应值是模型的输出。
      - 示例代码：
      {% raw %}
      {% for model_name in model_names %}
      model_module = __import__(model_name.replace('.py', ''))
      val_pred, test_pred, _ = model_module.model_workflow(
        X=train_X,
        y=train_y,
        val_X=val_X,
        val_y=val_y,
        test_X=X_test_transformed
      )
      val_preds_dict[model_module.__name__] = val_pred
      test_preds_dict[model_module.__name__] = test_pred
      {% endfor %}
      final_pred = ensemble_workflow(test_preds_dict, val_preds_dict, val_y)
      {% endraw %}
    
  Pipeline: |-
    1. 程序执行：
      - 工作流将通过运行 `python main.py` 且不带命令行参数来执行。确保 `main.py` 不需要或期望任何参数。
      - 工作目录将只包含 `main.py`。任何其他必需的文件必须由 `main.py` 自行下载或生成。
      {% if enable_notebook_conversion %}
      - 代码应该是模块化的并组织成函数，清晰的 main() 函数来协调工作流程。
        - 在 main() 函数内部，将代码划分为顺序部分。
          - 每个部分必须遵循这个确切的模式：
            - 一个打印部分名称的声明语句，例如 print("Section: <描述性名称>")
            - 1-2行注释解释该部分的目的
            - 该部分的代码块
          - 示例：
            ```python
            <任何辅助代码，导入，函数定义>

            def main():
                print("Section: Data Loading")
                # 从CSV将数据集加载到DataFrame
                # 处理缺失值
                <此部分的代码>

                print("Section: Feature Engineering")
                # 从原始数据生成新特征
                # 规范化和编码分类变量
                <此部分的代码>

                <函数的其余部分>

            <任何辅助代码>

            if __name__ == "__main__":
                main()
            ```
        - 部分标题必须始终在 main() 函数的顶层使用 print("Section: <name>")
          - 不要将它们放在 if/else 块内。
          - 不要将它们放在辅助函数内。
          - 不要将它们放在 main() 函数外。
        - 在打印语句之前不要添加评论或分隔符——评论必须在打印行之后。
        - 部分名称应简洁且具有描述性（例如，"Data Loading"，"Model Training"）。
        - 不要在 main() 函数中间调用 return 或 exit。如果需要提前停止执行，请引发异常。
      {% endif %}

    2. 文件处理：
      - 适当处理文件编码和分隔符。
      - 如有必要，合并或处理多个文件。
      - 避免使用 sample submission 文件来推断测试索引。如果有专用的测试索引文件，请使用该文件；否则，使用测试文件中的顺序作为测试索引。
      - 确保从文件加载实际数据，而不仅仅是文件名或路径。不要将数据加载推迟到后续步骤。

    3. 数据预处理：
      - 正确转换数据类型（例如，数值型、分类型、日期解析）。
      - 使用诸如降压或分块读取数据等技术优化大型数据集的内存使用。
      - 领域特定处理：
        - 根据需要应用竞赛特定的预处理步骤（例如，文本分词、图像调整大小）。

    4. 代码规范：
      - **重要提示：不要在代码中读取、加载或访问 sample_submission.csv 文件。从竞赛信息的 '====== Submission Format ======' 部分提取列名和格式要求。**
      - 不要使用进度条（例如 `tqdm`）。
      - 在此过程中不要意外排除特征。

    5. 注意事项
      - 切勿使用 sample submission 作为测试索引，因为它可能与测试数据不同。使用测试索引文件或测试数据源获取测试索引。

    6. 一般注意事项：
      - 确保大型数据集的可扩展性。
      - 适当处理缺失值和异常值（例如，填充、移除或替换）。
      - 确保特征数据类型和转换之间的一致性。
      - 防止数据泄露：不要在使用测试集信息转换训练数据时使用这些信息。
      - 除非能明显提高性能（例如，移除无关或异常样本），否则不建议对训练数据进行抽样（例如，随机选择部分数据）。

    7. 注意事项：
      - GPU和多进程可用，强烈建议用于加速转换。

    8. 指标计算和存储：
      - 计算每个模型和集成策略在验证集上的指标（竞赛信息的评估部分中提到），并将结果保存在 `scores.csv` 中
      - 评估应基于k折交叉验证，但如果这对于当前任务合适的话。将在每个模型的k折交叉验证的平均验证分数存储在 `scores.csv` 中。参考超参数规范以了解设置CV折数的规则。
      - 即使只有一个模型，也要计算集成分数并将其存储在"ensemble"下。
      - `scores.csv` 的索引应包括模型名称和"ensemble"策略。"ensemble"应完全小写（区分大小写）。Ensemble是多个模型的结果。如果只有一个模型，集成分数应与模型分数相同。
      - `scores.csv` 中的列名应为 ["{{ metric_name }}"]，其中 metric_name 是用于评估的指标名称。只需要一列。列名应与 "{{ metric_name }}" 完全相同（区分大小写），因为用户将使用它来选择结果。
      - 验证指标应在所有想法和实现中保持一致。避免提出可能影响验证指标并修改相关代码的想法。

    9. 提交文件：
      - 将最终预测保存为 `submission.csv`，确保格式符合竞赛要求，如竞赛信息的 '====== Submission Format ======' 部分所述（不要在代码中直接读取 sample_submission.csv 文件）。
      - 显式呈现所需的提交格式并确保输出符合要求。

    10. 首选包：
      - 你可以选择最合适的包来完成此任务。
      - 当面对两个都能实现相同目标的包时，你应该选择更常用且不太可能引起bug的包。特别是那些你不熟悉的包。
      - 对于GBDT模型，除非SOTA或假设另有要求，否则优先选择XGBoost或RandomForest而非LightGBM。
      - 要在训练中使用GPU，始终实施检查以确保GPU可用，并在可能的情况下使用它。如果GPU不可用，回退到CPU。尤其在GBDT模型中，调用 `fit` 方法而不检查GPU可用性可能会导致错误。添加 try except 块来处理这种情况。
      - 对于神经网络，除非SOTA或假设另有要求，否则优先选择PyTorch或基于PyTorch的库（而非TensorFlow）。
      - 对于神经网络，优先对预训练模型进行微调而非从零开始训练。

guidelines:
  coding: |-
    你可能会收到有关源数据的探索性数据分析（EDA）详细信息。**不要使用此EDA信息创建断言、硬编码值或引发错误。**我们可能会生成用于快速编码的样本数据（因此你的代码可能在作为完整数据一部分的样本数据上运行），但请记住，EDA详细信息基于完整数据。

spec:
  hyperparameter: |-
    1. 需要调优的超参数（例如学习率、权重衰减、优化器等）
      - 保守调整以避免不稳定。
      - 应用系统化的超参数调优策略来识别最优值。
    2. 依赖于经验估计或过去失败的超参数（例如批量大小、耐心值、轮数等）
      - 根据资源限制（例如运行时间限制）或从先前实验失败中获得的经验来估计这些参数。
    3. 平衡轮数和CV折数
      - 当运行时间允许时，优先增加训练轮数，但始终实施早停以防止过拟合并确保过程在允许的运行时间内完成。
      - 当运行时间受限时，首先减少CV折数——前提是验证可靠性仍然可接受——然后再减少轮数。
    4. 早停策略
      - 始终实施早停机制以防止过拟合并确保过程在允许的运行时间内完成。
      - 如果满足以下一个或多个条件，则停止训练：
        - 完成最少的轮数，并且所监控的指标在指定的耐心期内没有改善。
        - 验证损失（或指标）达到预定义的阈值，表示模型性能已足够。
        - 验证损失（或指标）保持稳定（即连续一定数量的轮数没有改善）。
      - 明确记录早停标准，并确保它们可通过超参数配置。
    5. 打印必要的信息到stdout以支持未来的优化和超参数调优。
      - 如果使用验证数据，请在训练期间打印早停的轮数/步骤，以及训练和验证损失。