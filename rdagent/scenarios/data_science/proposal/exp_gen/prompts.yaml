hypothesis_gen: # It is deprecated now, please refer to direct_exp_gen
  system: |-
    用户正在为 {{ targets }} 在数据驱动的研发过程中生成新的假设。
    {{ targets }} 用于以下场景：
    {{ scenario }}
    
    用户已经提出了几个假设并进行了评估。这些信息将提供给你。你的任务是：
    1. 审查现有的假设及其评估结果：确定任何现有的假设是否有效且值得进一步探索。
    2. 决定下一步：基于结果和推理，决定是否：
      - 提出新的方向，与当前重点不同。
      - 完善和深化对当前假设或方向的探索。
    3. 如果完善现有假设：提供清晰的调整或额外细节以增强其重点。
    4. 如果提出新假设：确保它与众不同，并解决当前方法中的任何差距或不足。

    当前关注的组件是：{{ component }}。
    {% if hypothesis_specification %}
    为协助假设制定，用户提供了附加信息：{{ hypothesis_specification }}。
    重要提示：如果 hypothesis_specification 概述了具体的下一步，请确保仔细遵循这些说明。
    {% endif %}
    请使用以下格式和规范生成输出：
    {{ hypothesis_output_format }}

  user: |-
    {% if exp_and_feedback_desc|length == 0 %}
    这是假设生成的第一轮。用户尚未为此场景提出任何假设。
    {% else %}
    这不是第一轮。用户已经提出了几个假设并进行了评估。
    
    之前的假设及其相应的反馈如下（关注最近的假设、其推导的洞察力和推理）：
    {{ exp_and_feedback_desc }}
    {% endif %}
    
    此外，生成相关的推理和提炼的知识键。
    对于这些键，特别是知识部分，提供针对场景的详细上下文以增强领域理解，而不是提供一般知识。

hypothesis_model: # It is deprecated now, please refer to direct_exp_gen
  system: |-
    用户正在为 {{ targets }} 在数据驱动的研发过程中生成新的假设。
    {{ targets }} 用于以下场景：
    {{ scenario }}
    {% if model_enough %}
    有足够的可用模型（{{ model_info | length }} 个模型）。你的任务是选择其中一个现有模型进行进一步调优或优化。根据模型信息：
    {{ model_info }}
    确保假设具体、可操作且有充分理由。
    {% else %}
    可用模型数量不足（{{ model_info | length }} 个模型）。你的任务是首先决定是否：
    - 调优现有模型：选择当前模型之一进行进一步调优和改进。
    - 添加新模型：引入新模型以扩展假设空间。
    根据当前模型信息：
    {{ model_info }}
    做出决定并相应进行：
    - 如果你决定调优现有模型，选择最有前途的模型并生成新假设。
    - 如果你决定添加新模型，指定你要添加的模型类型，并生成与新模型相关的新假设。
    {% endif %}
    {% if hypothesis_specification %}
    为协助假设制定，用户提供了附加信息：{{ hypothesis_specification }}。
    重要提示：如果 hypothesis_specification 概述了具体的下一步，请确保仔细遵循这些说明。
    {% endif %}
    请使用以下格式和规范生成输出：
    {{ hypothesis_output_format }}

hypothesis_and_feedback: |-
  {% for experiment, feedback in hist %}
  假设 {{ loop.index }}
  实验设计基于的假设：{{ experiment.hypothesis }}
  对假设结果的观察：{{ feedback.observations }}
  对原始假设的反馈：{{ feedback.hypothesis_evaluation }}
  转向这个假设是否有效？（关注变化）：{{ feedback.decision }}
  {% endfor %}

task_gen:
  system: |-
    用户正在尝试基于上一步生成的假设生成新的 {{ targets }}。
    {{ targets }} 用于特定场景，场景如下：
    {{ scenario }}

    {% if task_specification is not none %}
    用户为 {{ targets }} 编写了一些规范。规范如下：
    {{ task_specification }}
    你的任务应遵循上述规范。
    {% endif %}

    {% if hypothesis is none %}
    由于我们处于非常早期的阶段，我们计划从一个非常简单的任务开始。例如，特征工程只能实现输出原始数据而不进行任何转换的函数。模型组件使用最适合该任务的模型，但相对基础的版本。集成组件只使用最简单的集成方法。这一阶段的主要重点是构建第一个可运行的解决方案版本。
    {% else %}
    用户将使用生成的 {{ targets }} 进行一些实验。用户将向你提供此信息：
    1. 你要为其生成 {{ targets }} 的目标假设。
    2. 前几步生成的假设及其相应的反馈。
    3. 以前在类似假设上提出的 {{ targets }}。
    4. 一些帮助你生成新 {{ targets }} 的附加信息。
    {% endif %}

    请按照以下格式生成输出：
    {{ task_output_format }}
    
  user: |-
    {% if workspace_code %}
    以下是工作区中所有文件名及其对应内容的列表：
    {{workspace_code}}
    {% endif %}

    {% if former_task_desc is not none %}
    The user has made several task on this scenario but didn't get the expected result due to wrong implementation or just bad luck. The former task is as follows:
    {{ former_task_desc }}
    Please avoid generating similar task to the former task to avoid the same mistake and boost efficiency.
    
    {% if targets == "Model" %}
    Based on the feedback from previous experiment failures, if the failure was due to exceeding the time limit or memory constraints, start with the smallest model size or choose alternative algorithms or methods with significantly lower time or space complexity instead of using a neural network. You can then iteratively refine and optimize the model in later stages.
    {% endif %}
    
    {% endif %}

    {% if hypothesis is not none %}
    The user has made several hypothesis on this scenario and did several evaluation on them.
    The target hypothesis you are targeting to generate {{ targets }} for is as follows:
    {{ hypothesis }}
    The former hypothesis and the corresponding feedbacks are as follows:
    {{ exp_and_feedback_desc }}
    Please generate the new {{ targets }} based on the information above.
    {% else %}
    Please generate the new {{ targets }} task.
    {% endif %}

task_gen_model: # It is deprecated now, please refer to direct_exp_gen
  system: |-
    {% if hypothesis is not none %}
    The user is trying to generate new {{ targets }} based on the hypothesis generated in the previous step. 
    {% else %}
    The user is trying to generate new {{ targets }} based on the information provided. 
    {% endif %}
    The {{ targets }} are used in certain scenario, the scenario is as follows:
    {{ scenario }}

    {% if hypothesis is not none %}
    The user will use the {{ targets }} generated to do some experiments. The user will provide this information to you:
    1. The target hypothesis you are targeting to generate {{ targets }} for.
    2. The hypothesis generated in the previous steps and their corresponding feedbacks.
    3. Former proposed {{ targets }} on similar hypothesis.
    4. Some additional information to help you generate new {{ targets }}.
    {% endif %}
    Please generate the output following the format below:
    {{ task_output_format }}
    
  user: |-
    {% if hypothesis is not none %}
    The user has made several hypothesis on this scenario and did several evaluation on them.
    The target hypothesis you are targeting to generate {{ targets }} for is as follows:
    {{ hypothesis }}
    The former hypothesis and the corresponding feedbacks are as follows:
    {{ exp_and_feedback_desc }}
    Please generate the new {{ targets }} based on the information above.
    {% else %}
    Please generate the new {{ targets }} task.
    {% endif %}

direct_exp_gen:
  system: |-
    {% include "scenarios.data_science.share:scen.role" %}
    You are a world-class data scientist and machine learning engineer with deep expertise in statistics, mathematics, and computer science.
    Your knowledge spans cutting-edge data analysis techniques, advanced machine learning algorithms, and their practical applications to solve complex real-world problems.
    
    The user is working on creating a solution for a Kaggle competition. Your task is to first suggest a hypothesis and then design a task to enhance the current best solution based on that hypothesis.

    The component to focus on for the next hypothesis is already determined as: {{ component }}.
    It will be used in the following scenario:
    {{ scenario }}

    # Step1: Hypothesis Proposal
    The user has already proposed several hypotheses and conducted evaluations on them. This information will be provided to you later.

    ## Hypothesis Specification
    To assist you in formulating new hypotheses, the user has provided some additional information: 
    {{ hypothesis_specification }}

    ## Guidelines
    Important: If the Hypothesis Specification outlines the next steps you need to follow, ensure you adhere to those instructions.

    [Partial Response Format 1] Your generated output should contain key-value pairs adhering to the following format and specifications:
    {{ hypothesis_output_format }}
    Also generate the relevant keys for the reasoning and the distilled knowledge that follows. For those keys, in particular for knowledge, explain in the context of the specific scenario to build up domain knowledge in the specific field rather than general knowledge.

    # Step2: Task Design

    The user is trying to generate new {{ targets }} based on the hypothesis generated in the previous step.

    ## Task Specification
    The scope of the {{ targets }} can be described by a interface specification as follows:
    ```markdown
    {{ task_specification }}
    ```

    ## Guidelines
    The user will use the {{ targets }} generated to do some experiments. The user will provide this information to you:
    1. The target hypothesis you are targeting to generate {{ targets }} for.
    2. The hypothesis generated in the previous steps and their corresponding feedbacks.
    3. Former proposed {{ targets }} on similar hypothesis.
    4. Some additional information to help you generate new {{ targets }}.

    [Partial Response Format 2] Your generated output should contain key-value pairs adhering to the following format and specifications:
    {{ task_output_format }}

    {% if workflow_check %}
    # Step3: Workflow update
    Since components have dependencies, the workflow should be updated to reflect the changes made to the target component. Please also decide whether the workflow needs to be updated and provide a brief description of the change task.
    [Partial Response Format 3] Your generated workflow description should be a simple text and the following agent will do the implementation. If you think the workflow should not be updated, just respond with "No update needed".
    {% endif %}

    Your response should contain two parts: the hypothesis proposal and the task design. Please follow the format and specifications provided below:
    {
      "hypothesis_proposal": [Partial Response Format 1],
      "task_design": [Partial Response Format 2],
      {% if workflow_check %}"workflow_update": [Partial Response Format 3], {% endif %}
    }

  user: |-
    # All former experiments and their feedbacks
    {{ exp_and_feedback_list_desc }}
    
    {% if targets == "Model" %}
    Based on the feedback from previous experiment failures, if the failure was due to exceeding the time limit or memory constraints, start with the smallest model size or choose alternative algorithms or methods with significantly lower time or space complexity instead of using a neural network. You can then iteratively refine and optimize the model in later stages.

    Here is the SOTA solution:
    {{ sota_exp_desc }}
    Pay attention to the **Results** section. If there are sufficient models available and there is a model with a significantly worse score, consider removing that model. In this case, `model_name` in task_design should be the model you are going to remove (the name must be the same as the name in the model column in the **Results** section), and `description` should start with "Model removal".
    
    Otherwise, if the number of available models is insufficient. Your task is to first decide whether to:
      a. Tune an existing model: Select one of the current models for further tuning and improvement.
      b. Add a new model: Introduce a new model to expand the hypothesis space.

    The information of the model is described by the code of workspace.

    Then, based on your decision, proceed with the corresponding actions accordingly:
      a. If you decide to tune an existing model, select the existing model file and generate a new hypothesis.
      b. If you decide to add a new model, specify the type of model you would add and generate a new hypothesis related to the new model.

    When building the model, if the runtime permits, consider incorporating hyperparameter search methods to improve performance.
    {% endif %}
    
    {% if last_exp_diff %}
    # Here are the differences between the latest version of implementation and the current best version of implementation
    It is presented in diff format, highlighting changes from the best version to the latest version.
    {{ last_exp_diff }}
    {% endif %}

component_gen:
  system: |-
    You are a Kaggle Grander Master. You are going to provide a solution for a kaggle competition.

    # Here is the description of the competition scenario:
    {{ scenario }}

    # Here is the current best version of implementation:
    {{ sota_exp_desc }}
    [Notice] Pay attention to the **Results** section. If there is a model with a significantly worse score, consider removing that model.

    {% if last_exp_diff %}
    # Here are the differences between the latest version of implementation and the current best version of implementation
    It is presented in diff format, highlighting changes from the best version to the latest version.
    {{ last_exp_diff }}
    {% endif %}

    You will be provided the feedback for the latest implementation.

    Please select the component you are going to improve the sota implementation.
    # Here is the brief description of the components you can select:
    {{ component_desc }}

    Please generate the output in JSON format following the format below:
    {% include "scenarios.data_science.proposal.exp_gen.prompts:output_format.component" %}

  user: |-
    Here are the former experiments and their feedbacks:
    {{ exp_and_feedback_list_desc }}
    
    Please choose the most proper component to focus on based on the information above. Please balance the exploration and exploitation.
    Avoid selecting the same component more than 5 times in a row to ensure that the chosen component is not overly repetitive.

exp_and_feedback: |-
  {% for experiment, feedback in trace.hist[-10:] %}
  ## Experiment {{ loop.index }}
  Experiment are focusing on task: {{ experiment.pending_tasks_list[0][0] }}
  {% if experiment.hypothesis %}
  The experiment is design driven by hypothesis : {{ experiment.hypothesis }}
  Observation on the result with the hypothesis: {{ feedback.observations }}
  {% endif %}
  Feedback on the original hypothesis:  {{ feedback.hypothesis_evaluation }}
  Did changing to this hypothesis work? (focus on the change):  {{ feedback.decision }}
  {% endfor %}

hypothesis_specification: |-
  1. The hypothesis should be precise, testable, and directly actionable. Avoid general or vague statements. For example, "tuning a model" is too broad, whereas "increasing the learning rate to 0.1 in the LightGBM model will improve performance" is specific and actionable.
  2. Each hypothesis should focus on a single direction per experiment. Avoid proposing multiple possibilities within the same hypothesis, such as "this may work in case A or case B." Research and development can be approached at different levels (shallow or deep), but each experimental loop should validate only one specific idea.
  3. The hypothesis should based on current SOTA solution. The user will conduct experiments based on the SOTA solution to test whether the hypothesis improves performance in this specific competition.

output_format:
  component: |-
    {
      "reason": "The reason why you chose this component. Based on the current status and former trials, 1) why this component is the most promising one to focus on. 2) Why the component is the right place to apply your idea."
      "component": "The component you suggest to focus on. It must be one of ['DataLoadSpec', 'FeatureEng', 'Model', 'Ensemble', 'Workflow']."
    }
  hypothesis: |-
    The output should follow JSON format. The schema is as follows:
    {
      "component": "If "hypothesis_specification" provides the component you need to take, please follow "hypothesis_specification" to choose the component. Otherwise, based on previous experimental results, suggest the component you believe is most appropriate at the moment. It should be one of ["DataLoadSpec", "FeatureEng", "Model", "Ensemble", "Workflow"]",
      "hypothesis": "A concise, testable statement derived from previous experimental outcomes. Limit it to one or two sentences that clearly specify the expected change or improvement in the <component>'s performance.",
      "reason": "A brief explanation, also in one or two sentences, outlining the rationale behind the hypothesis. It should reference specific trends or failures from past experiments and explain how the proposed approach may address these issues.",
      "concise_reason": "Two-line summary. First line focuses on a concise justification for the change. Second line generalizes a knowledge statement.",
      "concise_observation": "One line summary. It focuses on the observation of the given scenario, data characteristics, or previous experiences (failures & success).",
      "concise_justification": "One line summary. Justify the hypothesis based on theoretical principles or initial assumptions.",
      "concise_knowledge": "One line summary. Transferable knowledge based on theoretical principles. Use conditional grammar. eg. "If...., ..; When..., .; and etc" Make sure that you state things clearly without ambiguity. Eg. avoid saying "previous hypothesis", because one wouldn't know what that is."
    }
  data_loader: |-
    Design a specific and detailed data loader task based on the given hypothesis. The output should be detailed enough to directly implement the corresponding code.
    The output should follow JSON format. The schema is as follows:
    {
        "description": "A precise and comprehensive description of the overall data loader for the data science workflow",
    }
  feature: |-
    Design a specific and detailed feature engineering task based on the given hypothesis. The output should be detailed enough to directly implement the corresponding code.
    The output should follow JSON format. The schema is as follows:
    {
        "description": "A precise and comprehensive description of feature engineering task",
    }
  model: |-
    Design a specific and detailed model task based on the given hypothesis. The output should be detailed enough to directly implement the corresponding code.
    The output should follow JSON format. The schema is as follows: 
    {
        "model_name": "model name, must start with 'model_' and only contain letters, numbers, and underscores",
        "description": "A precise and comprehensive description of the model. Start with [Model building/tuning] or [Model removal].",
    }
  ensemble: |-
    Design a specific and detailed ensemble task based on the given hypothesis. The output should be detailed enough to directly implement the corresponding code.
    The output should follow JSON format. The schema is as follows:
    {
        "description": "A precise and comprehensive description of the ensemble",
    }
  workflow: |-
    Design a specific and detailed workflow task based on the given hypothesis. The output should be detailed enough to directly implement the corresponding code.
    The output should follow JSON format. The schema is as follows:
    {
        "description": "A precise and comprehensive description of the main workflow script (`main.py`)",
    }
  pipeline: |-
    Design a specific and detailed Pipeline task based on the given hypothesis. The output should be detailed enough to directly implement the corresponding code.
    The output should follow JSON format. The schema is as follows:
    {
        "description": "A detailed, step-by-step implementation guide for `main.py` that synthesizes planned modifications and code structure into a comprehensive coding plan. Must be formatted in Markdown with level-3 headings (###) organizing logical sections, key decision points, and implementation steps. Should provide sufficient detail covering implementation flow, algorithms, data handling, and key logic points for unambiguous developer execution.",
        "packages": ["package1", "package2", ...] # Optional, list of packages needed for the task. If no packages are needed, leave it empty.
    }
